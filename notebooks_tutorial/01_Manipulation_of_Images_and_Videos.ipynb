{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div style=\"float: left; width: 50%; height: 200px; padding-bottom:40px\">\n",
    "    <img src=\"http://pydata.org/amsterdam2016/static/images/pydata-logo-amsterdam-2016.png\" alt=\"PyData Amsterdam 2016 Logo\">\n",
    "</div>\n",
    "<div style=\"float: right; width: 50%; height: 200px; padding-bottom:40px\">\n",
    "    <img style=\"height: 100%; float:right\" src=\"http://pydata.org/amsterdam2016/media/sponsor_files/qualogy_logo_350px.png\" alt=\"Qualogy Logo\">\n",
    "</div>\n",
    "\n",
    "# Building a Face Recognition System with OpenCV in the blink of an Eye\n",
    "\n",
    "This notebook was created for the tutorial during the PyData Meeting:\n",
    "- Author: <font color='#be2830'>Rodrigo Agundez from Qualogy</font>\n",
    "- Place: Papaverweg 265, Amsterdam\n",
    "- Date: <font color='#be2830'>Saturday March 12, 2016</font>\n",
    "- Time: <font color='#be2830'>16:15</font>\n",
    "- Room 2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The goal of this tutorial is to build a simple face recognition system with the use of the opencv library. This tutorial is separated in four parts:\n",
    "1. Manipulation of Images and Videoss\n",
    "2. Face Detection and Building the Dataset\n",
    "3. Building the Recognition Model\n",
    "4. Recognize Faces in a Live VIdeo Feed\n",
    "<br>Extra: Try to trick the face recognition to classify other types of objects.\n",
    "\n",
    "<br>\n",
    "<h2 align=\"center\" style='color: white; background-color: #be2830'>Let's Get Started!</h2> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h2 align=\"center\" style='color: #be2830'>Imports</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import cv2\n",
    "print cv2.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### A bit about OpenCV\n",
    "OpenCV is an open source computer vision and machine learning software library.\n",
    "The library includes a comprehensive set of both classic and state-of-the-art computer vision and machine learning algorithms. These algorithms can be used to:\n",
    "<div style=\"float: left; width: 40%; margin-top: 16px; margin-bottom: 16px\">\n",
    "<ul style=\"align: left; list-style-type:square\">\n",
    "  <li>Detect Faces</li>\n",
    "  <li>Recognize Faces</li>\n",
    "  <li>Identify Objects</li>\n",
    "  <li>Classify human actions in videos</li>\n",
    "  <li>Track camera movement</li>\n",
    "  <li>Track moving objects</li>\n",
    "</ul>\n",
    "</div>\n",
    "<div style=\"float: right; width: 60%; margin-top: 16px; margin-bottom: 16px\">\n",
    "<ul style=\"align: left; list-style-type:square\">\n",
    "  <li>Extract 3D models of objects</li>\n",
    "  <li>Produce 3D point clouds from stereo cameras</li>\n",
    "  <li>Stitch images together to produce a high resolution image of an entire scene</li>\n",
    "  <li>Find similar images from an image database</li>\n",
    "  <li>Remove red eyes from images taken using flash</li>\n",
    "  <li>Follow eye movements</li>\n",
    "</ul>\n",
    "</div>\n",
    "\n",
    "It has C++, C, Python, Java and MATLAB interfaces and supports Windows, Linux, Android and Mac OS. \n",
    "\n",
    "### Requiered Packages for this tutorial\n",
    "<ul style=\"list-style-type:square\">\n",
    "  <li>OpenCV (cv2)</li>\n",
    "  <li>Numpy</li>\n",
    "  <li>matpotlib</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2 align=\"center\" style='color: #be2830'>Let's Take  Picture</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "webcam = cv2.VideoCapture(0)\n",
    "ret, frame = webcam.read()\n",
    "print ret\n",
    "webcam.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h2 align=\"center\" style='color: #be2830'>How to show it?</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Resizable Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Open a new thread to manage the external cv2 interaction\n",
    "cv2.startWindowThread()\n",
    "\n",
    "# Create a window holder to show you image in\n",
    "cv2.namedWindow(\"PyData Tutorial\", cv2.WINDOW_NORMAL)\n",
    "cv2.imshow(\"PyData Tutorial\", frame)\n",
    " \n",
    "# Press any key to close external window\n",
    "cv2.waitKey()   \n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Fix Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Create a window holder to show you image in\n",
    "cv2.namedWindow(\"PyData Tutorial\", cv2.WINDOW_AUTOSIZE)\n",
    "cv2.imshow(\"PyData Tutorial\", frame)\n",
    "\n",
    "# Press any key to close external window\n",
    "cv2.waitKey() \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### What about within the notebook?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<h2 align=\"center\" style='color: #be2830'>Frame is a numpy array!</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "print type(frame) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Inside the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(frame)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Looks ugly, what happened?\n",
    "<div align=\"center\" style=\"margin-top:20px\"> \n",
    "OpenCV $\\rightarrow$ BGR format<br>\n",
    "matplotlib $\\rightarrow$ RGB\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### From BGR to RGB format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Pixel color conversion\n",
    "frame_RGB = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.imshow(frame_RGB)\n",
    "\n",
    "# Let's take those ugly ticks off\n",
    "plt.axis(\"off\") \n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2 align=\"center\" style='color: #be2830'>Read and Write Images</h2>\n",
    "\n",
    "``` python\n",
    "cv2.imwrite(file_path (str), image (numpy.ndarray))\n",
    "\n",
    "cv2.imread(file_path (str), read_mode (int))\n",
    "```\n",
    "#### Read Modes\n",
    "-  ```1 = cv2.IMREAD_COLOR```\n",
    "-  ```0 = cv2.IMREAD_GRAYSCALE```\n",
    "- ```-1 = cv2.IMREAD_UNCHANGED```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Write in GBR or RGB?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "cv2.imwrite('images/picture_GBR.jpg',frame)\n",
    "cv2.imwrite('images/picture_RGB.jpg',frame_RGB)\n",
    "\n",
    "os.system(\"nautilus images\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Read in GBR or RGB?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "read_mode = 1\n",
    "\n",
    "picture_GBR = cv2.imread('images/picture_GBR.jpg', read_mode)\n",
    "picture_RGB = cv2.imread('images/picture_RGB.jpg', read_mode)\n",
    "\n",
    "# numpy intervention\n",
    "picture = np.hstack((picture_GBR, picture_RGB))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"GBR   RGB\")\n",
    "plt.imshow(picture, cmap=\"Greys_r\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h2 align=\"center\" style='color: red'>OpenCV read & write</h2>\n",
    "\n",
    "| Image File |$\\rightarrow$|OpenCV     |$\\rightarrow$|Image File   |\n",
    "|:-----------:|:-----------:|:---------:|:-----------:|:-----------:|\n",
    "| .jpg .png etc| cv2.imread() | numpy array | cv2.imwrite() | .jpg .png etc |\n",
    "|RGB|$\\rightarrow$|GBR|$\\rightarrow$|RGB\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Useful function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def plt_show(image, title=\"\"):\n",
    "    if len(image.shape) == 3:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    plt.axis(\"off\") \n",
    "    plt.title(title)\n",
    "    plt.imshow(image, cmap=\"Greys_r\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2 align=\"center\" style='color: #be2830'>Let's Take  Video</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Open connection to camera\n",
    "webcam = cv2.VideoCapture(0)\n",
    "print webcam.isOpened()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### How to show it?\n",
    "1. Get a frame from webcam\n",
    "2. Show the frame\n",
    "3. Repeat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h2 align=\"center\" style='color: #be2830'>External Window or in Notebook</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### External Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "cv2.namedWindow(\"PyData Tutorial\", cv2.WINDOW_NORMAL)\n",
    " \n",
    "while True:\n",
    "      \n",
    "    _, frame = webcam.read()\n",
    "    cv2.imshow(\"PyData Tutorial\", frame) \n",
    "     \n",
    "    # code 27 is ESC key\n",
    "    if cv2.waitKey(20) & 0xFF == 27:\n",
    "        break\n",
    "        \n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "NOTE: Video feed killed but object still exists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### In Notebook\n",
    "Note: Since the notebook does not run as a tty device type getch() returns an error so we cannot catch a press key with this method. <br>\n",
    "`Instead KeyboardInterrupt` exception."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# module to allow interactive window inside notebook\n",
    "from IPython.display import clear_output\n",
    "try:\n",
    "    while True:\n",
    "        _, frame = webcam.read()\n",
    "        plt_show(frame)\n",
    "        clear_output(wait=True)\n",
    "except KeyboardInterrupt:\n",
    "    print \"Live Video Interrupted\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Slower, why? I don't really know"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Video feed killed but live video feed object still exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "webcam.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2 align=\"center\" style='color: #be2830'>Read and Write Videos</h2>\n",
    "\n",
    "``` python\n",
    "cv2.VideoCapture(file_path (str))\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(video_codec)\n",
    "\n",
    "container = cv2.VideoWriter(file_path (str), fourcc, frames_per_second (float), pixel_size (tuple))\n",
    "\n",
    "container.write(frame (np.ndarray))\n",
    "```\n",
    "#### Codecs\n",
    "-  ```XVID, MJPG, X264, DIVX, H264, etc. ```\n",
    "- Complete list of codecs in [www.fourcc.org](http://www.fourcc.org/codecs.php \"Wikipedia\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Reading a video - Display in External Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "video = cv2.VideoCapture(\"videos/video_test.avi\")\n",
    "print video.isOpened()\n",
    "\n",
    "cv2.namedWindow(\"PyData Tutorial\", cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow(\"PyData Tutorial\", 850, 480)\n",
    "\n",
    "while video.isOpened():\n",
    "    \n",
    "    ret, frame = video.read()  \n",
    "#     if not ret: \n",
    "#         break\n",
    "    \n",
    "#     frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "#     frame = cv2.flip(frame, 1)\n",
    "\n",
    "    cv2.imshow(\"PyData Tutorial\", frame)\n",
    "     \n",
    "    if cv2.waitKey(40) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "video.release()\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Reading a video - Display in Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "video = cv2.VideoCapture(\"videos/video_test.avi\")\n",
    "\n",
    "try:\n",
    "    while video.isOpened():\n",
    "        ret, frame = video.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        # REMEMBER width ---> columns, height ---> rows\n",
    "        width = frame.shape[1]\n",
    "        \n",
    "        frame = frame[:,width / 3:width,:]\n",
    "        plt_show(frame)\n",
    "        clear_output(wait=True)\n",
    "except KeyboardInterrupt:\n",
    "    print \"Video Interrupted\"\n",
    "video.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Recording and writing a video\n",
    "\n",
    "Waiting Time : time involved in cv2.waitKey()\n",
    "$$ FPS \\approx \\frac{1}{Waiting Time [seconds]} \\\\$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Using an External Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "webcam = cv2.VideoCapture(0)\n",
    "cv2.namedWindow(\"PyData Tutorial\", cv2.WINDOW_AUTOSIZE)\n",
    "# Define the codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "video = cv2.VideoWriter('videos/video_rod.avi',fourcc, 20.0, (640,480))\n",
    "\n",
    "while webcam.isOpened():\n",
    "    ret, frame = webcam.read()\n",
    "    video.write(frame)\n",
    "    # write/append to video object\n",
    "    cv2.imshow('PyData Tutorial',frame)\n",
    "    if cv2.waitKey(40) & 0xFF == 27:\n",
    "        break\n",
    "# release both video objects created\n",
    "webcam.release()\n",
    "video.release()\n",
    "cv2.destroyAllWindows()\n",
    "os.system(\"vlc videos/video_rod.avi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Using the Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "webcam = cv2.VideoCapture(0)\n",
    "# Define the codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "video = cv2.VideoWriter('videos/video_rod.avi',fourcc, 7, (640,480))\n",
    "try:\n",
    "    while webcam.isOpened():\n",
    "        ret, frame = webcam.read()\n",
    "        video.write(frame)\n",
    "        plt_show(frame)\n",
    "        clear_output(wait=True)\n",
    "except KeyboardInterrupt:\n",
    "    print \"Video capture stopped\"\n",
    "# release both video objects created\n",
    "webcam.release()\n",
    "video.release()\n",
    "cv2.destroyAllWindows()\n",
    "os.system(\"vlc videos/video_rod.avi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Display video using html\n",
    "```html\n",
    "<video src=\"video_rod.avi\"></video>\n",
    "```\n",
    "<div style=\"text-align: center\">\n",
    "    <video style=\"float: center\" src=\"videos/video_rod.avi\" controls></video>\n",
    "</div>\n",
    "\n",
    "<img src=\"images/video_support.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Using .mp4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "webcam = cv2.VideoCapture(0)\n",
    "cv2.namedWindow(\"PyData Tutorial\", cv2.WINDOW_AUTOSIZE)\n",
    "\n",
    "# Define the codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'H264')\n",
    "video = cv2.VideoWriter('videos/video_rod.mp4',fourcc, 20.0, (640,480))\n",
    "\n",
    "while webcam.isOpened():\n",
    "\n",
    "    ret, frame = webcam.read()\n",
    "    # write/append to video object\n",
    "    video.write(frame)\n",
    "    cv2.imshow('PyData Tutorial',frame)\n",
    "    if cv2.waitKey(40) & 0xFF == 27:\n",
    "        break\n",
    "        \n",
    "# release both video objects created\n",
    "webcam.release()\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Display video using html\n",
    "```html\n",
    "<video src=\"videos/video_rod.mp4\"></video>\n",
    "```\n",
    "<div style=\"text-align: center\">\n",
    "    <video style=\"float: center\" src=\"videos/video_rod.mp4\" controls></video>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2 align=\"center\" style='color: #be2830'>Drawing and Writing on Images/Videos</h2>\n",
    "\n",
    "``` python\n",
    "cv2.line(image, coord_1 (tuple), coord_2 (tuple), color_GBR (tuple), thickness (int))\n",
    "\n",
    "cv2.rectangle(image, top_left (tuple), bottom_right (tuple), color_GBR (tuple), thickness (int))\n",
    "\n",
    "cv2.circle(image, center (tuple), radius (int), color_GBR (tuple), thickness (int))\n",
    "\n",
    "cv2.ellipse(image, center (tuple), axes_length (tuple), angle (int), start_angle (int), end_angle (int), color (tuple), thickness (int))\n",
    "\n",
    "cv2.putText(image, text (str), bottom_left (tuple), font, size (float), color (tuple), thickness (int))\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Rectangle and dynamic typing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "webcam = cv2.VideoCapture(0)\n",
    "cv2.namedWindow(\"PyData Tutorial\", cv2.WINDOW_AUTOSIZE)\n",
    "message = \"\"\n",
    "\n",
    "while webcam.isOpened():\n",
    "    \n",
    "    _, frame = webcam.read()\n",
    "    \n",
    "    cv2.rectangle(frame, (100, 100), (530, 400), (150, 150, 0), 3)\n",
    "    cv2.putText(frame, message, (95, 95), cv2.FONT_HERSHEY_SIMPLEX, .7, \n",
    "                (150, 150, 0), 2)\n",
    "    \n",
    "    cv2.imshow('PyData Tutorial',frame)\n",
    "    key = cv2.waitKey(100) & 0xFF\n",
    "    if key not in [255, 27]:\n",
    "        message += chr(key)\n",
    "    elif key == 27:\n",
    "        break\n",
    "        \n",
    "# release both video objects created\n",
    "webcam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h2 align=\"center\" style='color: #be2830'>Using a Mask</h2>\n",
    "<br>\n",
    "<div style=\"float: left; width: 40%; padding-bottom:40px\">\n",
    "    <p> Stencil </p>\n",
    "    <img src=\"http://blog.speckproducts.com/blog/wp-content/uploads/2013/12/news_miamiMiniMaker-03_800w.jpg\">\n",
    "</div>\n",
    "<div style=\"float: right; width: 40%; padding-bottom:40px\">\n",
    "    <p> Semiconductors </p>\n",
    "    <img src=\"http://willson.cm.utexas.edu/Research/Sub_Files/Immersion/images/immersion_2.jpg\">\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### View through a circle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "webcam = cv2.VideoCapture(0)\n",
    "cv2.namedWindow(\"PyData Tutorial\", cv2.WINDOW_AUTOSIZE)\n",
    "\n",
    "while webcam.isOpened():\n",
    "    \n",
    "    _, frame = webcam.read()\n",
    "    mask = np.zeros_like(frame)\n",
    "    height, width, _ = frame.shape\n",
    "    \n",
    "    cv2.circle(mask, (width / 2, height / 2), 200, (255, 255, 255), -1)\n",
    "    frame = np.bitwise_and(frame, mask)\n",
    "    \n",
    "    cv2.imshow('PyData Tutorial', frame)\n",
    "    if cv2.waitKey(40) & 0xFF == 27:\n",
    "        break\n",
    "        \n",
    "# release both video objects created\n",
    "webcam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h2 align=\"center\" style='color: #be2830'>Handeling Mouse Events</h2>\n",
    "\n",
    "``` python\n",
    "cv2.setMouseCallback(window (str), callback_function)\n",
    "def function(event (int), x (int), y (int), )\n",
    "```\n",
    "<div style=\"float: left; width: 50%\">\n",
    "Events:\n",
    "- `cv2.EVENT_MOUSEMOVE`\n",
    "- `cv2.EVENT_LBUTTONDOWN`\n",
    "- `cv2.EVENT_RBUTTONDOWN`\n",
    "- `cv2.EVENT_MBUTTONDOWN`\n",
    "- `cv2.EVENT_LBUTTONUP`\n",
    "</div>\n",
    "<br>\n",
    "- `cv2.EVENT_RBUTTONUP`\n",
    "- `cv2.EVENT_MBUTTONUP`\n",
    "- `cv2.EVENT_LBUTTONDBLCLK`\n",
    "- `cv2.EVENT_RBUTTONDBLCLK`\n",
    "- `cv2.EVENT_MBUTTONDBLCLK`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Draw circle with mouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# mouse callback function\n",
    "def draw_circle(event,x,y,flags,param):\n",
    "    global x_in, y_in\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        x_in = x \n",
    "        y_in = y\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        cv2.circle(frame, (int((x + x_in)) / 2, int((y + y_in)/2)), \n",
    "                   int(math.sqrt((y - y_in) ** 2 + (x - x_in) ** 2) / 2), (150, 150, 0), -1)\n",
    "        \n",
    "cv2.namedWindow('PyData Tutorial')\n",
    "cv2.setMouseCallback('PyData Tutorial', draw_circle)\n",
    "\n",
    "webcam = cv2.VideoCapture(0)\n",
    "_, frame = webcam.read()\n",
    "webcam.release()\n",
    "\n",
    "while True:\n",
    "    cv2.imshow('PyData Tutorial',frame)\n",
    "    if cv2.waitKey(20) & 0xFF == 27:\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Using a mask to uncover image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# mouse callback function\n",
    "def draw_circle(event,x,y,flags,param):\n",
    "    global x_in, y_in\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        x_in = x \n",
    "        y_in = y\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        cv2.circle(mask, (int((x + x_in)) / 2, int((y + y_in)/2)), \n",
    "                   int(math.sqrt((y - y_in) ** 2 + (x - x_in) ** 2) / 2), \n",
    "                   (255, 255, 255), -1)\n",
    "        \n",
    "cv2.namedWindow('PyData Tutorial')\n",
    "cv2.setMouseCallback('PyData Tutorial', draw_circle)\n",
    "\n",
    "webcam = cv2.VideoCapture(0)\n",
    "_, frame = webcam.read()\n",
    "mask = np.zeros_like(frame)\n",
    "\n",
    "while True:\n",
    "    _, frame = webcam.read()\n",
    "    frame = np.bitwise_and(frame, mask)\n",
    "    cv2.imshow('PyData Tutorial', frame)\n",
    "    if cv2.waitKey(40) & 0xFF == 27:\n",
    "        break\n",
    "webcam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## NEXT\n",
    "<ol> \n",
    "    <h2> <li> Manipulation of Images and Videos. [DONE]</h2> \n",
    "    <h2 style='color: #be2830'><a style='color: #be2830' href=\"http://localhost:8888/notebooks/02_Face_Detection_and_Building_the_Dataset.ipynb\"> <li> Face Detection and Building the Dataset</a></h2>\n",
    "    <h2> <li>Building the Recognition Model</h2>\n",
    "    <h2> <li> Recognize Faces in a Live VIdeo Feed</h2>\n",
    "<ol>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
